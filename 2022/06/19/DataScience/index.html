<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>DataScience | 是甜豆腐脑</title><meta name="keywords" content="DataScience"><meta name="author" content="是甜豆腐脑"><meta name="copyright" content="是甜豆腐脑"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="此篇笔记记录数据科学课程第六章内容">
<meta property="og:type" content="article">
<meta property="og:title" content="DataScience">
<meta property="og:url" content="http://franny77.github.io/2022/06/19/DataScience/index.html">
<meta property="og:site_name" content="是甜豆腐脑">
<meta property="og:description" content="此篇笔记记录数据科学课程第六章内容">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://franny77.github.io/img/tx.JPG">
<meta property="article:published_time" content="2022-06-19T12:32:04.000Z">
<meta property="article:modified_time" content="2022-09-09T13:39:41.613Z">
<meta property="article:author" content="是甜豆腐脑">
<meta property="article:tag" content="DataScience">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://franny77.github.io/img/tx.JPG"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://franny77.github.io/2022/06/19/DataScience/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: ture
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DataScience',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-09 21:39:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/tx.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">是甜豆腐脑</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DataScience</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-19T12:32:04.000Z" title="发表于 2022-06-19 20:32:04">2022-06-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-09T13:39:41.613Z" title="更新于 2022-09-09 21:39:41">2022-09-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="DataScience"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第六章-建模与性能评价"><a href="#第六章-建模与性能评价" class="headerlink" title="第六章 建模与性能评价"></a>第六章 建模与性能评价</h1><h2 id="6-1-统计建模"><a href="#6-1-统计建模" class="headerlink" title="6.1 统计建模"></a>6.1 统计建模</h2><p>统计建模的实质：描述统计+推断统计（参数估计、假设检验）</p>
<h3 id="（1）基本概念回顾"><a href="#（1）基本概念回顾" class="headerlink" title="（1）基本概念回顾"></a>（1）基本概念回顾</h3><p>概率分布函数F(x)：给出取值小于某个值的概率，是概率的累加形式<br>概率密度函数f(x)：给出了变量落在某值邻域内（或者某个区间内）的概率变化快慢，概率密度函数的值不是概率，而是概率的变化率，概率密度函数下面的面积才是概率</p>
<h3 id="（2）常见的概率密度函数"><a href="#（2）常见的概率密度函数" class="headerlink" title="（2）常见的概率密度函数"></a>（2）常见的概率密度函数</h3><p>概率密度函数PDF：f(x)f(x)用来表示连续随机变量落在各值附近的可能性，给定f(x)f(x)后，X的一次抽样落入某区间的概率就等于概率密度函数f(x)f(x)在该区间上的积分，即<br><img src="https://img-blog.csdnimg.cn/83cb7ffcbf8149f481d2ec702106766c.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/6e2caedbf98b4362bdcd81c3cc66bd17.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b0777c241593470dbd57af595c90fd92.png" alt="在这里插入图片描述"></p>
<h4 id="2-正态分布（高斯分布）：概率密度函数为"><a href="#2-正态分布（高斯分布）：概率密度函数为" class="headerlink" title="2.正态分布（高斯分布）：概率密度函数为"></a>2.正态分布（高斯分布）：概率密度函数为</h4><p><img src="https://img-blog.csdnimg.cn/538e5880d23d4b229deb21dc61a6ac1b.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/657e1c0da1744d6a9280ba0d68e8c0bd.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b305858f78204b4398f211d063b80f2b.png" alt="在这里插入图片描述"></p>
<h4 id="3-t分布（学生t分布）："><a href="#3-t分布（学生t分布）：" class="headerlink" title="3.t分布（学生t分布）："></a>3.t分布（学生t分布）：</h4><p>根据小样本来估计呈正态分布且方差未知的总体均值。样本容量小于30时，样本均值不符合正态分布，则可以将均值标准化后构造一个统计量t，统计量t是符合t分布的，在t分布中做均值估计和区间估计。<br>构造统计量t：<br><img src="https://img-blog.csdnimg.cn/684aaf26448541a58bd1c3307f1d9dab.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/11fcfa12f8bf467fa6b0c82c5be27b90.png" alt="在这里插入图片描述"><br>t分布的概率密度函数是由自由度df控制的一簇曲线，t分布的自由度是样本容量n-1，曲线关于t&#x3D;0对称，样本容量越小，曲线越平坦；样本容量越大，曲线越接近正态分布。（小样本估计依据）</p>
<h4 id="4-卡方分布"><a href="#4-卡方分布" class="headerlink" title="4.卡方分布"></a>4.卡方分布</h4><p><img src="https://img-blog.csdnimg.cn/97187c9d5ea442029015124a80783f9a.png" alt="在这里插入图片描述"></p>
<h3 id="3-参数估计"><a href="#3-参数估计" class="headerlink" title="3.参数估计"></a>3.参数估计</h3><p>基于样本统计量X&#x2F;E(X)或s而对总体分布参数μ或σ进行估计</p>
<h4 id="①均值点估计："><a href="#①均值点估计：" class="headerlink" title="①均值点估计："></a>①均值点估计：</h4><p>依据中心极限定律，来源于同一总体的独立随机抽样的算术平均服从均值μ的正态分布，所以样本的统计均值就是总体均值的无偏估计，记为：<br><img src="https://img-blog.csdnimg.cn/7e629d469c034d228ad2089762a31192.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> sample</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats <span class="comment"># python的stats模块提供了大量统计学常用函数</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1234</span>) <span class="comment"># 设置随机数种子方便实验结果的复现</span></span><br><span class="line">my_data1 = stats.poisson.rvs(loc = <span class="number">10</span>, mu = <span class="number">60</span>, size = <span class="number">3000</span>) <span class="comment"># 生成一个规定均值的泊松分布</span></span><br><span class="line">pd.Series(my_data1).hist().get_figure().show <span class="comment"># 作直方图展示</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一个均值分布是:70,\t统计平均是:&quot;</span>, my_data1.mean()) <span class="comment"># 均值人为规定，统计平均直接计算，看是否和指定的均值一致</span></span><br><span class="line">my_data2 = stats.poisson.rvs(loc = <span class="number">10</span>, mu = <span class="number">15</span>, size = <span class="number">6000</span>)</span><br><span class="line">pd.Series(my_data1).hist().get_figure().show</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一个均值分布是:25,\t统计平均是:&quot;</span>, my_data2.mean())</span><br><span class="line">my_data = np.concatenate((my_data1, my_data2)) <span class="comment"># numpy.ndarray对象的连接</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总体的均值为:&quot;</span>, my_data.mean())</span><br><span class="line">sample_data = np.random.choice(a = my_data, size = <span class="number">100</span>) <span class="comment"># 从总体中取100个样本计算样本均值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本的均值为:&quot;</span>, sample_data.mean())</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	第一个均值分布是:70,    统计平均是: 69.97966666666666</span></span><br><span class="line"><span class="string">	第一个均值分布是:25,    统计平均是: 25.009333333333334</span></span><br><span class="line"><span class="string">	总体的均值为: 39.99944444444444</span></span><br><span class="line"><span class="string">	样本的均值为: 39.3</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/aaf3b581e9e34d17ad123f108ffbbba7.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>以上代码用到的具体方法：<br>np.random.seed()方法：用于指定随机数生成时所用算法开始的整数值，如果使用相同的值，则每次生成的随机数都相同<br> np.concatenate()方法：用于连接 np.ndarray 对象 pd.Series( )方法：将一个列表、np.ndarray 对象转化为 pandas.Series 对象<br> np.random.choice( a, size &#x3D; )方法：从a随机抽取数字，并组成指定 size的数组 具体参数：<br> a np.ndarray 对象<br> size 整数 指定抽取样本的个数<br>stats.poisson.rvs( loc &#x3D; , mu &#x3D; , size &#x3D; )方法：从泊松分布中生成指定个数的随机数，rvs 表示产生服从指定分布的随机数<br>具体参数：<br> loc 与 mu 两者共同决定这个分布的均值（两者之和） size 整数 生成随机数的个数</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">验证中心极限定律</span><br><span class="line">point_estimates = [] <span class="comment"># 一个列表，用于存放每次抽样的样本均值</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    sample = np.random.choice(a = my_data, size = <span class="number">100</span>) <span class="comment"># 抽取100个样本</span></span><br><span class="line">    point_estimates.append(sample.mean()) <span class="comment"># 计算样本的均值并存入列表</span></span><br><span class="line">pd.DataFrame(point_estimates).hist(bins = <span class="number">40</span>) <span class="comment"># 将列表转换为pandas.DataFrame对象后画直方图展示</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本均值的均值为:&quot;</span>, np.array(point_estimates).mean()) <span class="comment"># 将列表转化为np.ndarray对象后可以利用mean()方法计算平均值</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	样本均值的均值为: 39.95712</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/b53760eca1654065829d3d66818b4705.png" alt="在这里插入图片描述">样本均值趋于正态分布</p>
<h4 id="②均值区间估计："><a href="#②均值区间估计：" class="headerlink" title="②均值区间估计："></a>②均值区间估计：</h4><p>对于总体进行的独立随机抽样，样本均值会分布在一个范围里，对于一个给定的置信水平，就可以求得一个置信区间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sample = np.random.choice(a = my_data, size = <span class="number">100</span>)</span><br><span class="line">sigma = sample.std()/(sample_size) ** <span class="number">0.5</span> <span class="comment"># 构造t统计量的分母</span></span><br><span class="line"><span class="built_in">print</span>(stats.t.interval(alpha = <span class="number">0.95</span>, df = sample_size - <span class="number">1</span>, loc = sample.mean(), scale = sigma)) <span class="comment"># 求置信区间</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	(36.29263468910625, 45.26736531089375)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>以上代码用到的方法：<br>stats.t.interval( alpha &#x3D; , df &#x3D; , loc &#x3D; , scale &#x3D; )方法：用于针对t分布求置信区间<br>具体参数如下<br>alpha 浮点数 代表置信水平<br>df 整数 代表t分布的自由度，一般取样本容量-1<br>loc 浮点数 代表构造t统计量需要的样本均值<br>scale 浮点数 代表构造t统计量需要的分母sigma</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line">![在这里插入图片描述](https://img-blog.csdnimg.cn/f4d0c8b7df324099beb8fe4704d7cf51.png)</span><br><span class="line"></span><br><span class="line">### 4.假设检验</span><br><span class="line">通常做法是：提出一个假设，验证是否可以接受该假设</span><br><span class="line"></span><br><span class="line">假设检验的基本思想：反证法</span><br><span class="line">在假定某个假设是正确的情况下构造一个小概率事件，如果在一次试验里小概率事件发生了，则拒绝这个假设</span><br><span class="line"></span><br><span class="line">假设检验的相关概念：</span><br><span class="line">Ⅰ空假设\零假设：待检验的假设，用H0</span><br><span class="line">​</span><br><span class="line"> 表示（一般事物的惯常态，概率大）</span><br><span class="line">TIP：常见的零假设：总体的均值等于μ；测试组和对照组来源于均值相等的总体；控制因素对观察变量没有影响，A组和B组数据同分布</span><br><span class="line"></span><br><span class="line">Ⅱ替代假设\备择假设：空假设的对立，用H1</span><br><span class="line">​</span><br><span class="line"> 表示（概率小）</span><br><span class="line">TIP：常见的备择假设：总体的均值不等于μ；测试组和对照组来源于均值不等的总体；控制因素对观察变量有影响，A组和B组数据不同分布</span><br><span class="line"></span><br><span class="line">Ⅲ显著性水平：统计检验时需要将从样本获取的统计量与显著性水平比较（p值与alpha值的比较），一般人为定义（取0.05）</span><br><span class="line"></span><br><span class="line">假设检验的一般步骤：</span><br><span class="line">①确定总体和sample size（适中）</span><br><span class="line">②收集数据</span><br><span class="line">③确定H0 和H1</span><br><span class="line">④设置显著性水平alpha</span><br><span class="line">⑤选择并计算相应的统计量，进行假设检验</span><br><span class="line">⑥根据统计量或假设检验的p值与显著性水平的比较决定拒绝或接受H0</span><br><span class="line"></span><br><span class="line">![在这里插入图片描述](https://img-blog.csdnimg.cn/86fa64051a624ca7bf70eb46ff525f22.png)</span><br><span class="line"></span><br><span class="line">​假设检验类型：</span><br><span class="line">①t检验—均值的单样本检验：对单组样本的均值进行假设检验</span><br><span class="line">t检验：借助t统计量服从t分布</span><br><span class="line">Ⅰ.单样本双边均值检验：</span><br><span class="line">假设H0：总体均值等于μ </span><br><span class="line"> 对应H1：总体均值不等于\muμ</span><br><span class="line">Ⅱ.单样本单边均值检验：将不等于换成大于或小于</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">单样本双边均值检验代码举例：</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy import stats</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.stats import t # t检验</span><br><span class="line"></span><br><span class="line"># 生成一个含有9000样本的总体</span><br><span class="line">np.random.seed(1234)</span><br><span class="line">my_data1 = stats.poisson.rvs(loc = 10, mu = 60, size = 3000)</span><br><span class="line">my_data2 = stats.poisson.rvs(loc = 10, mu = 15, size = 6000)</span><br><span class="line">my_data = np.concatenate((my_data1, my_data2))</span><br><span class="line"></span><br><span class="line"># 假设</span><br><span class="line">print(&quot;空假设H0是:总体的均值是47.5\n&quot;) # 假设的总体均值可由(70+25)/2得来</span><br><span class="line"></span><br><span class="line"># 检验</span><br><span class="line">sample_data = np.random.choice(a = my_data, size = 100) # 抽样</span><br><span class="line">t_statistic, p_value = stats.ttest_1samp(a = sample_data, popmean = 47.5) # 计算得到t统计量和p值</span><br><span class="line">print(&quot;从样本构造的t统计量 = &quot;, t_statistic)</span><br><span class="line">print(&quot;p = &quot;, p_value)</span><br><span class="line"></span><br><span class="line"># 画出t分布图像</span><br><span class="line">df = 100 - 1 # 设置自由度</span><br><span class="line">x = np.linspace(stats.t.ppf(0.00000001, df), stats.t.ppf(0.99999999, df), 100)</span><br><span class="line">plt.plot(x, t.pdf(x, df))</span><br><span class="line">str_legend = (&quot;t distribution&quot;, &quot;calculated t&quot;)</span><br><span class="line">plt.legend(str_legend)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">	输出结果</span><br><span class="line">	空假设H0是:总体的均值是47.5</span><br><span class="line">	从样本构造的t统计量 = -3.7405281096559153</span><br><span class="line">	p = 0.00030786517310847877</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure>
<p>以上代码用到的具体方法：<br>stats.ttest_1samp( a &#x3D; , popmean &#x3D; )方法：返回a样本集的t统计量与p值，一般用两个变量t_statistic和p_value去接收<br>具体参数：<br>a np.ndarray 对象 代表样本集<br>popmean 浮点数 代表零检验中的期望值</p>
<p>np.linspace(start, end, num &#x3D; )方法：用于在线性空间中以均匀步长生成数字序列<br>具体参数：<br>start 范围起始<br>end 范围结束<br>num 序列中的总点数</p>
<p>stats.t.ppf( )方法：用来求分位点（在图像中确定了曲线边界）<br>stats.t.pdf( )方法：用来生成概率密度函数表（在图像中对应了纵坐标）</p>
<p>plt.legend( legend &#x3D; )方法：用于定义图例<br>具体参数：<br>legend 元组 内含图例的名字</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">![在这里插入图片描述](https://img-blog.csdnimg.cn/466f1334721a4f62863dc2a6f51e39c4.png)</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">alpha = 0.05 # 人为定义alpha值</span><br><span class="line">if p_value &gt; 0.05:</span><br><span class="line">    print(&quot;接受 H0&quot;)</span><br><span class="line">else:</span><br><span class="line">    print(&quot;拒绝 H0, 即总体的均值不等于47.5, 此时错误拒绝H0的概率为&quot;, p_value, &quot;小于显著性水平&quot;)</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">	输出结果</span><br><span class="line">	拒绝 H0,即总体的均值不等于47.5, 此时错误拒绝H0的概率为0.00030786517310847877 小于显著性水平</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure>

<p>②t检验—均值的双样本检验：两组数据间的均值比较<br><img src="https://img-blog.csdnimg.cn/96ab4f1ca1fd47dda26d5f9b5964d8df.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> t</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个总体</span></span><br><span class="line">np.random.seed(<span class="number">1234</span>)</span><br><span class="line">my_data1 = stats.poisson.rvs(loc = <span class="number">10</span>, mu = <span class="number">60</span>, size = <span class="number">3000</span>)</span><br><span class="line">my_data2 = stats.poisson.rvs(loc = <span class="number">10</span>, mu = <span class="number">15</span>, size = <span class="number">6000</span>)</span><br><span class="line">my_data = np.concatenate((my_data1, my_data2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造两组样本，存放于字典</span></span><br><span class="line">my_sample = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    my_sample[n] = np.random.choice(a = my_data, size = <span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&quot;</span>, n, <span class="string">&quot;组样本的均值为&quot;</span>,my_sample[n].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 双样本均值检验</span></span><br><span class="line">alpha = <span class="number">0.01</span> <span class="comment"># 人为规定置信水平</span></span><br><span class="line">t_statistic, p_value = stats.ttest_rel(a = my_sample[<span class="number">0</span>], b = my_sample[<span class="number">1</span>]) <span class="comment"># 计算得到t统计量和p值（这里假设不知道总体的方差是否相等，所以优先取用ttest_rel方法）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;t = &quot;</span>, t_statistic)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p = &quot;</span>, p_value)</span><br><span class="line"><span class="keyword">if</span> p_value &lt;= alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝 H0:两样本来源的总体均值相等&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;接受 H0:两样本来源的总体均值相等&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	第 0 组样本的均值为 39.3</span></span><br><span class="line"><span class="string">	第 1 组样本的均值为 41.14</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	t =  -0.5797156447793128</span></span><br><span class="line"><span class="string">	p =  0.5634233550606107</span></span><br><span class="line"><span class="string">	接受 H0:两样本来源的总体均值相等</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>③z检验：当样本容量大于30或样本容量小于30但已知潜在总体服从正态分布时，t分布由正态分布取代，t检验也由z检验取代</p>
<p>④卡方检验：研究两组类别型数据在某一特征上的概率分布是否一致时，通常利用卡方检验<br>假设H0:组A的分布与组B一致<br>对应H1：组A与分布与组B不一致<br>举例：检验titanic数据中幸存者是否是女多男少时，则只需要比较幸存者在性别特征的两个分类别（男、女）的分布情况，则可以做出如下假设：<br>假设H0 :幸存者中的性别分布与船上所有人的性别分布一致<br>对应H1:幸存者中的性别分布与船上所有人的性别分布不一致</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> chi2 <span class="comment"># 卡方检验</span></span><br><span class="line"></span><br><span class="line">titanic = pd.read_csv(<span class="string">&quot;titanic.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算船上所有人的男女比例</span></span><br><span class="line">mask1 = titanic[<span class="string">&quot;Sex&quot;</span>] == <span class="string">&quot;male&quot;</span> <span class="comment"># 返回的是pandas.Series对象</span></span><br><span class="line">mask2 = titanic[<span class="string">&quot;Sex&quot;</span>] == <span class="string">&quot;female&quot;</span></span><br><span class="line">p = np.array([<span class="built_in">sum</span>(mask1) / (<span class="built_in">sum</span>(mask1) + <span class="built_in">sum</span>(mask2)), <span class="built_in">sum</span>(mask2) / (<span class="built_in">sum</span>(mask1) + <span class="built_in">sum</span>(mask2))])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;船上的男女比例为:&quot;</span>, p)</span><br><span class="line"></span><br><span class="line">mask_survived = titanic[<span class="string">&quot;Survived&quot;</span>] == <span class="number">1</span> <span class="comment"># 返回的是pandas.Series对象，内含索引号与一个布尔类型，代表是否存活</span></span><br><span class="line">my_survived = titanic.loc[mask_survived, <span class="string">&#x27;Sex&#x27;</span>] <span class="comment"># 获取指定行，loc里面的mask_survived代表指定的行索引，&#x27;Sex&#x27;是需要获取的内容，得到的是pandas.Series对象，只含有行序号和性别</span></span><br><span class="line">pop_size = my_survived.count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;存活的人共有:&quot;</span>, pop_size)</span><br><span class="line"></span><br><span class="line">E = pop_size * p</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预期的男、女个数为:&quot;</span>, E)</span><br><span class="line"></span><br><span class="line">mask1 = my_survived == <span class="string">&quot;male&quot;</span> <span class="comment"># 得到一个pandas.Series对象，内含索引号与一个布尔类型，代表是否是男性</span></span><br><span class="line">mask2 = my_survived == <span class="string">&quot;female&quot;</span></span><br><span class="line">my_set1 = my_survived[mask1]</span><br><span class="line">my_set2 = my_survived[mask2]</span><br><span class="line">O = np.array([<span class="built_in">len</span>(my_set1), <span class="built_in">len</span>(my_set2)])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;实际的男、女个数为:&quot;</span>, O)</span><br><span class="line"></span><br><span class="line">chi_squard, p_value = stats.chisquare(f_obs = O, f_exp = E) <span class="comment"># 卡方检验，得到卡方统计量与p值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卡方检验的p = &quot;</span>, p_value)</span><br><span class="line"></span><br><span class="line">a = <span class="number">0.05</span> <span class="comment"># 人为规定的置信水平</span></span><br><span class="line"><span class="keyword">if</span> p_value &lt;= a:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;拒绝 男性、女性具有相同生存率的假设&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;接受 男性、女性具有相同生存率的假设&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	船上的男女比例为: [0.64758698 0.35241302]</span></span><br><span class="line"><span class="string">	存活的人共有: 342</span></span><br><span class="line"><span class="string">	预期的男、女个数为: [221.47474747 120.52525253]</span></span><br><span class="line"><span class="string">	实际的男、女个数为: [109 233]</span></span><br><span class="line"><span class="string">	卡方检验的p = 3.970516389658729e-37</span></span><br><span class="line"><span class="string">	拒绝 男性、女性具有相同生存率的假设（逃生时确实做到女士优先）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">以上代码用到的具体方法：</span><br><span class="line">stats.chisquare( f_obs = , f_exp = )方法：返回卡方统计量与p值，一般用两个变量chi_squard和p_value去接收</span><br><span class="line">具体参数：</span><br><span class="line">f_obs 数组 在每个类别中观察的频率</span><br><span class="line">f_exp 数组 在每个类别中预期的频率</span><br></pre></td></tr></table></figure>
<h4 id="5-p-hacking"><a href="#5-p-hacking" class="headerlink" title="5.p-hacking"></a>5.p-hacking</h4><p>即便p&lt;alpha，拒绝空假设还是存在错误拒绝的风险，错误拒绝的概率为p<br>即便空假设成立，当随机尝试100种不同的特征时，出现5个落入拒绝域的特征也是完全合理的<br>避免过度挖掘数据——p-hacking（操作p值）</p>
<h2 id="6-2-回归模型"><a href="#6-2-回归模型" class="headerlink" title="6.2 回归模型"></a>6.2 回归模型</h2><p>回归指建立因变量y与自变量x之间的函数关系：<br><img src="https://img-blog.csdnimg.cn/d256470bcfa7437983373d9d18394b22.png" alt="在这里插入图片描述"></p>
<p> 代表用f获得的对y的估计（或预测）<br>回归分类：<br>一元回归：x只包含一个特征<br>多元回归：x包含多个特征<br>线性回归：函数关系f是线性的<br>非线性回归：函数关系f是非线性的</p>
<h4 id="（1）线性回归模型：一元线性回归为例"><a href="#（1）线性回归模型：一元线性回归为例" class="headerlink" title="（1）线性回归模型：一元线性回归为例"></a>（1）线性回归模型：一元线性回归为例</h4><p>建立因变量y与一维特征xx的线性函数关系：<br><img src="https://img-blog.csdnimg.cn/55d4346ba67c44de8197a8b4f22592bc.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/d183b17f58e54d6092166ba4920ff06b.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2cd8b5d785f54a2a932330d016a8f70c.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="comment"># 线性回归需要导入的库</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> alpha_dropout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">my_iris = pd.read_csv(<span class="string">&quot;iris.csv&quot;</span>, sep = <span class="string">&#x27;,&#x27;</span>, decimal = <span class="string">&#x27;.&#x27;</span>, header = <span class="literal">None</span>, names = [<span class="string">&quot;sepal_length&quot;</span>, <span class="string">&quot;sepal_width&quot;</span>, <span class="string">&quot;petal_length&quot;</span>, <span class="string">&quot;petal_width&quot;</span>, <span class="string">&quot;target&quot;</span>])</span><br><span class="line"></span><br><span class="line">x = my_iris[[<span class="string">&quot;petal_length&quot;</span>]] <span class="comment"># 提取需要的特征列，返回pandas.DataFrame对象</span></span><br><span class="line">y = np.array(my_iris[<span class="string">&quot;sepal_length&quot;</span>]) <span class="comment"># 提取目标列,返回np.ndarray对象</span></span><br><span class="line">plt.plot(x, y, alpha = <span class="number">0.5</span>) <span class="comment"># 绘制这些数据点</span></span><br><span class="line"></span><br><span class="line">linreg = LinearRegression() <span class="comment"># 创建一个线性回归模型实例</span></span><br><span class="line">linreg.fit(x, y) <span class="comment"># 模型训练</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;f(x) = &quot;</span>, linreg.intercept_, <span class="string">&quot;+&quot;</span>, linreg.coef_[<span class="number">0</span>], <span class="string">&quot;x&quot;</span>) <span class="comment"># 把回归系数和截距以公式的形式显示</span></span><br><span class="line"></span><br><span class="line">pred_y = linreg.predict(x) <span class="comment"># 模型预测</span></span><br><span class="line">plt.plot(x, pred_y, <span class="string">&#x27;g&#x27;</span>, alpha = <span class="number">0.5</span>) <span class="comment"># 将预测曲线也画在图上</span></span><br><span class="line">plt.plot(np.array(x).mean(), y.mean(), <span class="string">&quot;r*&quot;</span>, ms = <span class="number">12</span>) <span class="comment"># 把回归直线必过的点用五角星强调</span></span><br><span class="line">plt.gca().set_xlabel(feature_cols)</span><br><span class="line">plt.gca().set_ylabel(<span class="string">&quot;sepal_length&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;RMSE = &quot;</span>, np.sqrt(metrics.mean_squared_error(y, pred_y))) <span class="comment"># 计算RMSE并输出</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	f(x) =  4.305565456292049 + 0.4091258984678836 x</span></span><br><span class="line"><span class="string">	RMSE =  0.40435105064202476</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e0c762a837aa42b0a41eadd1ba5f9502.png" alt="在这里插入图片描述"><br>以上代码用到的方法<br>LinearRegression( )方法：创建一个线性回归模型的实例<br>模型实例.fit(x, y)方法：用于模型训练，x代表特征，y代表目标<br>模型实例.predict(x)方法：用于预测，x代表预测对象的特征<br>线性回归模型的intercept_属性：代表截距<br>线性回归模型的linreg.coef_[0]属性：代表回归系数<br>metrics.mean_squared_error( y_true, y_pred )方法：计算均方误差，y_true代表真实值，y_pred代表预测值，返回np.float64类型<br>np.sqrt( )方法：计算给定数组中每个元素的平方根</p>
<h4 id="（2）线性回归模型性能评价标准"><a href="#（2）线性回归模型性能评价标准" class="headerlink" title="（2）线性回归模型性能评价标准"></a>（2）线性回归模型性能评价标准</h4><p><img src="https://img-blog.csdnimg.cn/86cc375d71704d24b908de4fd71cea84.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;r_square = &quot;</span>, linreg.score(x, y))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	r_square =  0.7599553107783261</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>以上代码用到的方法：<br>模型实例.score( )方法：返回模型的评价分数<br>在线性回归模型中评价分数就是决定系数</p>
<h4 id="（3）线性回归与线性相关"><a href="#（3）线性回归与线性相关" class="headerlink" title="（3）线性回归与线性相关"></a>（3）线性回归与线性相关</h4><p>线性回归中的决定系数就是线性相关系数的平方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(my_iris[[feature_cols, <span class="string">&quot;sepal_length&quot;</span>]].corr()) <span class="comment"># 求两两特征的线性相关系数</span></span><br><span class="line">r = np.array(my_iris[[feature_cols, <span class="string">&quot;sepal_length&quot;</span>]].corr()[[<span class="string">&quot;sepal_length&quot;</span>]].iloc(<span class="number">0</span>)[<span class="number">0</span>]) <span class="comment"># 完成提取后仍是np.ndarray对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;r = &quot;</span>, r)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;square of r = &quot;</span>, r ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	              petal_length  sepal_length</span></span><br><span class="line"><span class="string">	petal_length      1.000000      0.871754</span></span><br><span class="line"><span class="string">	sepal_length      0.871754      1.000000</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">	r =  [0.87175416]</span></span><br><span class="line"><span class="string">	square of r =  [0.75995531]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="（4）逻辑回归模型"><a href="#（4）逻辑回归模型" class="headerlink" title="（4）逻辑回归模型"></a>（4）逻辑回归模型</h4><p>基于一个或多个量化特征&#x2F;自变量直接预测某件事发生的概率，由于概率取值0~1，故采用Logistic函数（Logistic函数输出预测变量——某事发生概率）<br><img src="https://img-blog.csdnimg.cn/323e4c65ad464ab487ac12525cf8772c.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">table = pd.DataFrame(&#123;<span class="string">&#x27;prob&#x27;</span>:[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.99</span>]&#125;)</span><br><span class="line">table[<span class="string">&#x27;odds&#x27;</span>] = table[<span class="string">&#x27;prob&#x27;</span>]  / (<span class="number">1</span> - table[<span class="string">&#x27;prob&#x27;</span>])</span><br><span class="line">table[<span class="string">&#x27;log-odds&#x27;</span>] = np.log(table[<span class="string">&#x27;odds&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(table)</span><br><span class="line"></span><br><span class="line">plt.plot(table[<span class="string">&#x27;prob&#x27;</span>], table[<span class="string">&#x27;prob&#x27;</span>], <span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.plot(table[<span class="string">&#x27;prob&#x27;</span>], table[<span class="string">&#x27;odds&#x27;</span>], <span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.plot(table[<span class="string">&#x27;prob&#x27;</span>], table[<span class="string">&#x27;log-odds&#x27;</span>], <span class="string">&#x27;m&#x27;</span>)</span><br><span class="line">plt.plot(<span class="number">0.5</span>, <span class="number">0</span>, <span class="string">&#x27;dr&#x27;</span>, ms = <span class="number">10</span>)</span><br><span class="line">plt.ylim([-<span class="number">6</span>, <span class="number">6</span>])</span><br><span class="line">plt.legend([<span class="string">&#x27;probability&#x27;</span>, <span class="string">&#x27;Odds&#x27;</span>, <span class="string">&#x27;log_odds&#x27;</span>, <span class="string">&#x27;(0.5, 0)&#x27;</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	   prob       odds  log-odds</span></span><br><span class="line"><span class="string">	0  0.10   0.111111 -2.197225</span></span><br><span class="line"><span class="string">	1  0.20   0.250000 -1.386294</span></span><br><span class="line"><span class="string">	2  0.30   0.428571 -0.847298</span></span><br><span class="line"><span class="string">	3  0.40   0.666667 -0.405465</span></span><br><span class="line"><span class="string">	4  0.50   1.000000  0.000000</span></span><br><span class="line"><span class="string">	5  0.60   1.500000  0.405465</span></span><br><span class="line"><span class="string">	6  0.70   2.333333  0.847298</span></span><br><span class="line"><span class="string">	7  0.80   4.000000  1.386294</span></span><br><span class="line"><span class="string">	8  0.90   9.000000  2.197225</span></span><br><span class="line"><span class="string">	9  0.99  99.000000  4.595120</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/8e3ba3509e9542a5afbe4a67f837515d.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/1934cc995b2f47a1954a3aa3a95ac8c1.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="comment"># 逻辑回归需要导入的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment"># 用于划分训练集、测试集</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">bikes = pd.read_csv(<span class="string">&quot;bikeshare.csv&quot;</span>) <span class="comment"># 读取数据集</span></span><br><span class="line"><span class="built_in">print</span>(bikes.shape) <span class="comment"># 输出数据集的基本信息</span></span><br><span class="line"></span><br><span class="line">x = bikes[[<span class="string">&#x27;temp&#x27;</span>]] <span class="comment"># 将temp列作为特征（注意返回pandas.DataFrame对象）</span></span><br><span class="line">y = bikes[<span class="string">&#x27;count&#x27;</span>] &gt;= bikes[<span class="string">&#x27;count&#x27;</span>].mean() <span class="comment"># 返回的是pandas.Series对象，内含索引号与一个布尔类型，代表是否数量大于平均值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y)</span><br><span class="line"></span><br><span class="line">logreg = LogisticRegression() <span class="comment"># 实例化一个模型对象</span></span><br><span class="line">logreg.fit(x_train, y_train) <span class="comment"># 拿训练集训练模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分类的准确率为:&quot;</span>, logreg.score(x_test, y_test)) <span class="comment"># 利用测试集得到模型准确率</span></span><br><span class="line"><span class="built_in">print</span>(pd.DataFrame(np.transpose([y_test.values, logreg.predict(x_test)]), columns = &#123;<span class="string">&#x27;真实值&#x27;</span>, <span class="string">&#x27;预测值&#x27;</span>&#125;).head()) <span class="comment"># 将预测的测试集结果和实际的测试集结果组合拼接成一个二维数组，经过转置后再经过类型转换，生成pandas.DataFrame对象并返回前几行</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">	分类的准确率为: 0.6697281410727406</span></span><br><span class="line"><span class="string">       预测值 真实值</span></span><br><span class="line"><span class="string">	0  False  False</span></span><br><span class="line"><span class="string">	1   True  False</span></span><br><span class="line"><span class="string">	2  False  False</span></span><br><span class="line"><span class="string">	3  False   True</span></span><br><span class="line"><span class="string">	4  False   True</span></span><br><span class="line"><span class="string">	（原数组真实值在上，预测值在下；故而转置后预测值在前，真实值在后）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">以上代码用到的方法：</span><br><span class="line">train_test_split(x, y, test_size = , random_state = )方法：用于随机划分训练集和测试集，通常用四个变量接收，分别代表：训练集特征、训练集目标、测试集特征、测试集目标</span><br><span class="line">具体参数：</span><br><span class="line">x 数据框 所有特征的集合</span><br><span class="line">y 数组/序列 所有目标取值</span><br><span class="line">test_size 浮点数/整数 训练集样本占比/训练集样本数量</span><br><span class="line">random_state 随机数的种子</span><br><span class="line"></span><br><span class="line">np.transpose( a )方法：调换数组的行列值的索引值（求转置）返回一个 np.ndarray 对象</span><br><span class="line">具体参数：</span><br><span class="line">a 数组 想要进行转置的数组</span><br></pre></td></tr></table></figure>
<h4 id="（5）训练集—测试集划分"><a href="#（5）训练集—测试集划分" class="headerlink" title="（5）训练集—测试集划分"></a>（5）训练集—测试集划分</h4><p>模型使用的两个阶段：<br>阶段：模型建立fit(X, Y)→模型应用predict(X)<br>任务：确定模型参数（在已有数据上最优）→基于已有模型对新数据预测<br>数据：X已知，Y已知→X已知，期待模型输出Y</p>
<p>数据足够多时，把文件分成两个集合：训练集与测试集，基于训练集进行建模，再对模型在测试集数据上的表现评分，最后用于预测</p>
<h4 id="（6）非数值型特征作为输入时的-one-hot-编码"><a href="#（6）非数值型特征作为输入时的-one-hot-编码" class="headerlink" title="（6）非数值型特征作为输入时的 one-hot 编码"></a>（6）非数值型特征作为输入时的 one-hot 编码</h4><p>非数值型特征中的数字没有真实的数量意义<br>举例：”季节”特征的1~4代表四个季节，但数字本身不含有数量意义</p>
<p>one-hot 编码：避免数字引入非真实数量意义，将类别型数据映射到一个始终只有一位置为”1”，其他位都是”0”的二进制编码，编码长度就是类别个数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">bikes[<span class="string">&#x27;above_average&#x27;</span>] = bikes[<span class="string">&#x27;count&#x27;</span>] &gt;= bikes[<span class="string">&#x27;count&#x27;</span>].mean() <span class="comment"># 返回的是pandas.Series对象，内含索引号与一个布尔类型，代表是否数量大于平均值，这里用数据集的新列去接受</span></span><br><span class="line">bikes.groupby(<span class="string">&#x27;season&#x27;</span>).above_average.mean().plot(kind = <span class="string">&#x27;bar&#x27;</span>) <span class="comment"># 统计各季节有多少大于平均数量（作出柱状图简单比较哪个季节数量较多）</span></span><br><span class="line">plt.show()</span><br><span class="line">when_dummies = pd.get_dummies(bikes[<span class="string">&#x27;season&#x27;</span>], prefix = <span class="string">&#x27;season_&#x27;</span>) <span class="comment"># 对季节采用one-hot编码</span></span><br><span class="line"><span class="built_in">print</span>(when_dummies.head()) <span class="comment"># 展示出one-hot编码后的季节特征前几行</span></span><br><span class="line"></span><br><span class="line">x = pd.concat([bikes[[<span class="string">&#x27;temp&#x27;</span>]], when_dummies], axis = <span class="number">1</span>) <span class="comment"># 将自行车数据的气温特征和one-hot编码列连接作为训练集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y)</span><br><span class="line">logreg = LogisticRegression() <span class="comment"># 实例化一个模型的对象</span></span><br><span class="line">logreg.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用气温、季节同时作为预测自变量,预测的准确率为:&quot;</span>, logreg.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">x = bikes[[<span class="string">&#x27;temp&#x27;</span>, <span class="string">&#x27;season&#x27;</span>]] <span class="comment">#将自行车数据的气温特征和季节特征列连接作为训练集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y)</span><br><span class="line">logreg = LogisticRegression() <span class="comment">#实例化一个模型对象</span></span><br><span class="line">logreg.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;用气温、季节同时作为预测自变量，但是不做季节特征的one-hot编码时,预测的准确率为:&quot;</span>, logreg.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	输出结果</span></span><br><span class="line"><span class="string">		season__1  season__2  season__3  season__4</span></span><br><span class="line"><span class="string">	 0          1          0          0          0</span></span><br><span class="line"><span class="string">	 1          1          0          0          0</span></span><br><span class="line"><span class="string">	 2          1          0          0          0</span></span><br><span class="line"><span class="string">	 3          1          0          0          0</span></span><br><span class="line"><span class="string">	 4          1          0          0          0</span></span><br><span class="line"><span class="string">	用气温、季节同时作为预测自变量,预测的准确率为: 0.6914033798677444</span></span><br><span class="line"><span class="string">	用气温、季节同时作为预测自变量,但是不做季节特征的one-hot编码时,预测的准确率为: 0.6337252020573108</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/7fd0001c5a5f45909a3dc311809dd2f2.png" alt="在这里插入图片描述"></p>
<h2 id="6-3-朴素贝叶斯模型"><a href="#6-3-朴素贝叶斯模型" class="headerlink" title="6.3 朴素贝叶斯模型"></a>6.3 朴素贝叶斯模型</h2><h4 id="1-贝叶斯定理"><a href="#1-贝叶斯定理" class="headerlink" title="1.贝叶斯定理"></a>1.贝叶斯定理</h4><p><img src="https://img-blog.csdnimg.cn/be9bc793acfa4156b7830a34de8bbca6.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/737b44b44bfa4ee49e902655ebd8e2fd.png" alt="在这里插入图片描述"></p>
<h4 id="（2）高斯模型"><a href="#（2）高斯模型" class="headerlink" title="（2）高斯模型"></a>（2）高斯模型</h4><p>当特征xx在每一类中都是服从高斯分布的连续值时构建的模型<br>sklearn库中的native_bayes模块有GaussianNB对象可以构建朴素贝叶斯的高斯模型</p>
<h4 id="（3）多项式模型"><a href="#（3）多项式模型" class="headerlink" title="（3）多项式模型"></a>（3）多项式模型</h4><p>当特征本身是离散值时构建的模型<br>sklearn库中的native_bayes模块有MultinomialNB对象可以构建朴素贝叶斯的多项式模型</p>
<h4 id="（4）伯努利模型"><a href="#（4）伯努利模型" class="headerlink" title="（4）伯努利模型"></a>（4）伯努利模型</h4><p>当特征xx是m个布尔值序列时构建的模型<br>sklearn库中的native_bayes模块有BernoulliNB对象可以构建朴素贝叶斯的伯努利模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklean.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklean.naive_bayes <span class="keyword">import</span> BernoulliNB</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">GaussianNB().fit()</span><br><span class="line">GaussianNB().predict()</span><br><span class="line"></span><br><span class="line">MultinomialNB().fit()</span><br><span class="line">MultinomialNB().predict()</span><br><span class="line"></span><br><span class="line">BernoulliNB().fit()</span><br><span class="line">BernoulliNB().predict()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>未完待续…</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://FraNny77.github.io">是甜豆腐脑</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://franny77.github.io/2022/06/19/DataScience/">http://franny77.github.io/2022/06/19/DataScience/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://FraNny77.github.io" target="_blank">是甜豆腐脑</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DataScience/">DataScience</a></div><div class="post_share"><div class="social-share" data-image="/./img/tx.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/07/12/Regularization/"><img class="prev-cover" src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Regularization</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/17/%E3%80%8A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"><img class="next-cover" src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">《人间失格》读后感</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/tx.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">是甜豆腐脑</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/FraNny77.io"><i class="fab fa-github"></i><span>Gituhub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/FraNny77" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2556725169@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://blog.csdn.net/FraNny13" target="_blank" title="Blog"><i class="fab fa-algolia"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E5%BB%BA%E6%A8%A1%E4%B8%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7"><span class="toc-text">第六章 建模与性能评价</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E7%BB%9F%E8%AE%A1%E5%BB%BA%E6%A8%A1"><span class="toc-text">6.1 统计建模</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%9B%9E%E9%A1%BE"><span class="toc-text">（1）基本概念回顾</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-text">（2）常见的概率密度函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%EF%BC%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%EF%BC%89%EF%BC%9A%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E4%B8%BA"><span class="toc-text">2.正态分布（高斯分布）：概率密度函数为</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-t%E5%88%86%E5%B8%83%EF%BC%88%E5%AD%A6%E7%94%9Ft%E5%88%86%E5%B8%83%EF%BC%89%EF%BC%9A"><span class="toc-text">3.t分布（学生t分布）：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%8D%A1%E6%96%B9%E5%88%86%E5%B8%83"><span class="toc-text">4.卡方分布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="toc-text">3.参数估计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0%E5%9D%87%E5%80%BC%E7%82%B9%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">①均值点估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1%E5%9D%87%E5%80%BC%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">②均值区间估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-p-hacking"><span class="toc-text">5.p-hacking</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-text">6.2 回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%BA%E4%BE%8B"><span class="toc-text">（1）线性回归模型：一元线性回归为例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86"><span class="toc-text">（2）线性回归模型性能评价标准</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3"><span class="toc-text">（3）线性回归与线性相关</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-text">（4）逻辑回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%885%EF%BC%89%E8%AE%AD%E7%BB%83%E9%9B%86%E2%80%94%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-text">（5）训练集—测试集划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E9%9D%9E%E6%95%B0%E5%80%BC%E5%9E%8B%E7%89%B9%E5%BE%81%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5%E6%97%B6%E7%9A%84-one-hot-%E7%BC%96%E7%A0%81"><span class="toc-text">（6）非数值型特征作为输入时的 one-hot 编码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-text">6.3 朴素贝叶斯模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-text">1.贝叶斯定理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-text">（2）高斯模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B"><span class="toc-text">（3）多项式模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%A8%A1%E5%9E%8B"><span class="toc-text">（4）伯努利模型</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/14/MybatisNotes/" title="MybatisNotes"><img src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MybatisNotes"/></a><div class="content"><a class="title" href="/2022/09/14/MybatisNotes/" title="MybatisNotes">MybatisNotes</a><time datetime="2022-09-14T01:42:07.000Z" title="发表于 2022-09-14 09:42:07">2022-09-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/09/spiderNotes/" title="spyderNotes"><img src="http://cache.yisu.com/upload/admin/customer_case_img/2019-08-08/1565261709.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="spyderNotes"/></a><div class="content"><a class="title" href="/2022/09/09/spiderNotes/" title="spyderNotes">spyderNotes</a><time datetime="2022-09-09T12:34:08.000Z" title="发表于 2022-09-09 20:34:08">2022-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/14/3%20.%20Gradient%20descent/" title="3. Gradient descent"><img src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="3. Gradient descent"/></a><div class="content"><a class="title" href="/2022/07/14/3%20.%20Gradient%20descent/" title="3. Gradient descent">3. Gradient descent</a><time datetime="2022-07-14T06:15:56.000Z" title="发表于 2022-07-14 14:15:56">2022-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/13/1.Regression/" title="1. Regression"><img src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="1. Regression"/></a><div class="content"><a class="title" href="/2022/07/13/1.Regression/" title="1. Regression">1. Regression</a><time datetime="2022-07-13T07:21:44.000Z" title="发表于 2022-07-13 15:21:44">2022-07-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/13/2.%20Error%20origin/" title="2. Error origin"><img src="http://imgoss.cnu.cc/2204/27/a4383d0f926b346eb1fe8ff128e5b703.jpg?x-oss-process=style/content" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2. Error origin"/></a><div class="content"><a class="title" href="/2022/07/13/2.%20Error%20origin/" title="2. Error origin">2. Error origin</a><time datetime="2022-07-13T06:45:40.000Z" title="发表于 2022-07-13 14:45:40">2022-07-13</time></div></div></div></div></div></div></main><footer id="footer" style="background: #000000"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 是甜豆腐脑</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">试着和曾经仰望的人并肩</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>